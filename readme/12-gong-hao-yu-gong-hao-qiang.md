# 1-2功耗与功耗墙

## CPU的极限

前一部分（1-性能-CPU）中说明了，要提高计算机性能，可以从指令数、CPI 以及 CPU 主频这三个地方入手（CPU响应时间=指令数×CPI/CPU主频）

于是从1978 年 Intel 发布的 8086 CPU 开始，计算机的主频从 5MHz 开始不断提升直到 2000 年的奔腾 4 处理器，主频已经到达了 1.4GHz。且 Intel 表示奔腾 4 所使用的 CPU 结构可以做到 10GHz。

但最终它的主频上限定格在 3.8GHz，且它的实际性能却配不上同样的主频。

想要用在笔记本上的奔腾 4 2.4GHz 处理器，其性能只和基于奔腾 3 架构的奔腾 M 1.6GHz 处理器差不多。

其代表着“主频时代”的终结。后面几代 Intel CPU 主频不但没有上升，反而下降了。

到2019年，最高配置 Intel i9 CPU，主频也只不过是 5GHz 而已。

相较于 1978 年到 2000 年，这 20 年里 300 倍的主频提升，从 2000 年到现在的这 19 年，CPU 的主频大概提高了 3 倍。

> 奔腾 4 的主频为什么没能超过 3.8GHz 的障碍呢？答案就是功耗问题。

## 功耗

### 对比案例

一个 3.8GHz 的奔腾 4 处理器，满载功率是 130 W，即一小时耗电130Wh（1kWh=1度电）。而 iPhone X 使用 ARM 架构的 CPU，功率则只有 4.5 W左右。

### 影响CPU功耗因素

CPU，一般都被叫作**超大规模集成电路**（Very-Large-Scale Integration，VLSI）。这些电路，实际上都是一个个晶体管组合而成的

CPU 在计算，其实就是让晶体管里面的“开关”不断地去“打开”和“关闭”，来组合完成各种运算和功能。

想要提高CPU性能，即：提升主频，使CPU计算得更快：

* 一方面，我们要在 CPU 里，同样的面积里面，多放一些晶体管，即**增加晶体管密度**
* 另一方面，我们要让晶体管“打开”和“关闭”得更快一点，即通过**改进晶体管工艺水平**

这两者，都会增加功耗，带来耗电和散热的问题。

### 功耗带来的问题

> 耗电量增大、温度过高使CPU奔溃（或降频）

* 如果功耗过大，散热不足会导致温度过高，CPU就会崩溃出错（或降频）
* 因此，在 CPU 里面，能够放下的晶体管数量和晶体管的“开关”频率也都是有限的。
* 功耗 ≈ 1/2 ×负载电容×电压的平方×开关频率×晶体管数量

## 在功耗问题下的性能提升

### 提高CPU主频

* 增加密度，改进晶体管工艺水平
  * 增加晶体管可以增加硬件能够支持的指令数量，增加数字通路的位数，可减少程序所需指令数，以及利用电路天然的并行性，从硬件层面更快地实现特定的指令
  * 同样的面积下，我们想要多放一点晶体管，就要把晶体管造得小一点，即平时我们所说的提升“制程”：如果从 28nm 到 7nm，相当于晶体管本身变成了原来的 1/4 大小
  * 同时我们还要改进晶体管工艺水平，让开关的频率变快
* 降低电压，减少功耗
  * 如果功耗增加太多，就会导致 CPU 散热跟不上，这时，我们就需要降低电压
  * 在整个功耗的公式里面，功耗和电压的平方是成正比的。这意味着电压下降到原来的 1/5，整个的功耗会变成原来的 1/25
  * 从 5MHz 主频的 8086 到 5GHz 主频的 Intel i9，CPU 的电压已经从 5V 左右下降到了 1V 左右。
  * 所以我们 CPU 的主频提升了 1000 倍，但是功耗只增长了 40 倍。
  * 比如Surface Go这样的轻薄笔记本上，微软就是选择了把电压下降到 0.25V 的低电压 CPU，使得笔记本能有更长的续航时间。
  * 限制：电压不能过低
    * 电压太低就会导致电路无法联通，所以没有办法无限制降低电压
    * 低电压对于工艺的要求更高，成本也更贵

### 提高吞吐率 - 通过并行提高性能

* 通过多核CPU进行并行计算提高吞吐率

#### 并行计算条件

并不是所有问题，都可以通过并行计算解决，并行计算有以下三个限制

1. 需要进行的计算，本身可以分解成几个可以并行的任务。好比上面的乘法和加法计算，几个人可以同时进行，不会影响最后的结果。
2. 需要能够分解好问题，并确保几个人的结果能够汇总到一起。
3. 在“汇总”这个阶段，是没有办法并行进行的，还是得顺序执行。

#### 阿姆达尔定律

对于一个程序进行优化之后，处理器并行运算之后效率提升的情况，可以用这样一个公式来表示：

$优化后的执行时间 = 受优化影响的执行时间 / 加速倍数 + 不受影响的执行时间$

例：比如向量 `W=[W0,W1,W2,…,W15]`和向量 `X=[X0,X1,X2,…,X15]`做点积：`W·X=W0∗X0+W1∗X1+W2∗X2+…+W15∗X15`

这些式子由 16 个乘法和 1 个连加组成。如果一个人来算的话，需要算 16 次乘法和 15 次加法

如果这个时候我们把这个任务分配给 4 个人，同时去算 0～3, 4～7, 8～11, 12～15 这样四个部分的结果，再由一个人进行汇总，需要的时间就会缩短

这4 个人同时计算向量的一小段点积，就是通过并行提高了这部分的计算性能。其中，最后在一个人那里进行汇总相加的时间，是不能通过并行来优化的，也就是上面的公式里面**不受影响的执行时间**这一部分。

比如上面做向量点积的乘法部分，需要 100ns，加法需要 20ns，总共需要 120ns。这里通过并行 4 个 CPU 有了 4 倍的加速度。那么最终优化后，就有了 100/4+20=45ns。即使我们增加更多的并行度来提供加速倍数，比如有 100 个 CPU，整个时间也需要 100/100+20=21ns。

![](<../.gitbook/assets/image (1).png>)

## 非硬件层面提升性能

### 1. 加速大概率事件

最典型的就是，过去几年流行的深度学习，整个计算过程中，99% 都是向量和矩阵计算，于是，工程师们通过用 GPU 替代 CPU，大幅度提升了深度学习的模型训练过程。本来一个 CPU 需要跑几小时甚至几天的程序，GPU 只需要几分钟就好了。Google 更是不满足于 GPU 的性能，进一步地推出了 TPU

### 2. 通过流水线提高性能

CPU 其实就是一个“运算工厂”。我们把 CPU 指令执行的过程进行拆分，细化运行，也是现代 CPU 在主频没有办法提升那么多的情况下，性能仍然可以得到提升的重要原因之一。

### 3. 通过预测提高性能

通过预先猜测下一步该干什么，而不是等上一步运行的结果，提前进行运算，也是让程序跑得更快一点的办法。典型的例子就是在一个循环访问数组的时候，凭经验，你也会猜到下一步我们会访问数组的下一项。后面要讲的“分支和冒险”、“局部性原理”这些 CPU 和存储系统设计方法，其实都是在利用我们对于未来的“预测”，提前进行相应的操作，来提升我们的程序性能。

1.加速大概率事件\
可能如 Redis 缓存、CDN 内容分发网络、游戏开发中常用的对象池等 各种缓存(内存缓存、CDN缓存)\
JIT 运行时编译, 可以通过profiling数据, 将小概率甚至死代码排除, 只运行有效部分 2.流水线\
可能如多线程开发、分布式系统、DDOS攻击等 并发编程、异步编程\
音视频播放器边播放边缓冲 3.预测 小说的下一页预加载 浏览器预加载 电商大促的CDN预热

## 性能与功耗部分总结

影响性能的两个主要因素：吞吐率、响应时间

* 其中响应时间=指令数\*平均指令执行时间/CPU主频

CPU主频由工艺技巧和晶体管密度决定，受功耗制约

同样大小空间下，晶体管密度受晶体管制程影响，即晶体管多大 14nm、7nm、5nm...

功耗 = 1/2\*电容\*电压平方\*开关频率\*晶体管数

功耗过高，如果散热不足会导致温度过高，使CPU奔溃出错或降频拉低性能

降低功耗其中一种相当有效的方式是降低电压，不过电压过低会导致CPU无法工作，且低电压的工艺要求高，成本高

* 另一种方法是提高吞吐率 - 通过并行计算

通过多核实现并行计算

并行计算要求计算是可分割、能汇总的，且汇总时结果不受影响

并行计算下，在汇总阶段仍然需要顺序计算

判断并行计算的效率提升情况可以通过阿姆达尔定律确定

优化后的执行时间 = 受影响的时间/加速倍数 + 不受影响的时间

提高CPU权衡的两个案例：

* 轻薄笔记本很多采用降频CPU，能够减少功耗，节能且减少散热负担
* 超频中常用的手段即为降低电压
